{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('final_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = data[data[\"type\"] == \"Foodbank\"].reset_index()\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(filtered[\"demand\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered[\"demand\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete \"lat\", \"lng\", \"type\",\"demand\", \"supply\", \"waste\" columns\n",
    "filtered.drop(columns=[\"lat\", \"lng\", \"type\",\"demand\", \"supply\", \"waste\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered[\"name\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import gamma\n",
    "import pandas as pd\n",
    "\n",
    "# Parameters\n",
    "N = 249                             # Total number of samples\n",
    "p_zero = 0.85                       # Proportion of zeros\n",
    "desired_total_sum = 25000           # Desired total sum\n",
    "\n",
    "# Initialize 'filtered' DataFrame with 'name' column\n",
    "# Assume 'names_list' is your list of names corresponding to each sample\n",
    "names_list = [f\"Sample {i+1}\" for i in range(N)]  # Replace with your actual names\n",
    "\n",
    "filtered = pd.DataFrame({'name': filtered[\"name\"].to_list()})\n",
    "\n",
    "# Compute adjusted mean and standard deviation\n",
    "mu_total = desired_total_sum / N    # New mean to achieve the desired total sum\n",
    "original_CV = 680.29 / 166.71       # Original coefficient of variation (CV â‰ˆ 4.08)\n",
    "sigma_total = original_CV * mu_total\n",
    "sigma_total_sq = sigma_total ** 2\n",
    "\n",
    "# Precompute constants outside the loop\n",
    "n_zeros = int(p_zero * N)           # Number of zeros\n",
    "n_nonzeros = N - n_zeros            # Number of non-zeros\n",
    "p_nonzero = 1 - p_zero\n",
    "mu_zero = 0\n",
    "\n",
    "# Mean of non-zero data\n",
    "total_sum = mu_total * N            # Total sum of data\n",
    "mu_nonzero = total_sum / n_nonzeros\n",
    "\n",
    "# Variance of non-zero data using the law of total variance\n",
    "delta_mu_zero = mu_zero - mu_total\n",
    "delta_mu_nonzero = mu_nonzero - mu_total\n",
    "\n",
    "sigma_zero_sq = 0                   # Variance of zeros is zero\n",
    "sigma_nonzero_sq = (\n",
    "    sigma_total_sq\n",
    "    - p_zero * delta_mu_zero ** 2\n",
    "    - p_nonzero * delta_mu_nonzero ** 2\n",
    ") / p_nonzero\n",
    "\n",
    "sigma_nonzero = np.sqrt(sigma_nonzero_sq)\n",
    "\n",
    "# Gamma distribution parameters\n",
    "shape = (mu_nonzero ** 2) / sigma_nonzero_sq\n",
    "scale = sigma_nonzero_sq / mu_nonzero\n",
    "\n",
    "# Generate zeros and gamma-distributed non-zero values outside the loop\n",
    "zeros = np.zeros(n_zeros)\n",
    "max_value = 6640  # Maximum value to clip the gamma samples\n",
    "\n",
    "for i in range(366):\n",
    "    # Generate gamma-distributed non-zero values for the day\n",
    "    gamma_samples = gamma.rvs(a=shape, scale=scale, size=n_nonzeros)\n",
    "\n",
    "    # Clip values to the maximum value\n",
    "    gamma_samples = np.clip(gamma_samples, a_min=None, a_max=max_value)\n",
    "\n",
    "    # Combine zeros and gamma samples\n",
    "    data = np.concatenate([zeros, gamma_samples])\n",
    "\n",
    "    # Shuffle the data\n",
    "    np.random.shuffle(data)\n",
    "\n",
    "    # Assign data to the DataFrame, ensuring the 'name' column is preserved\n",
    "    filtered[f\"Day {i+1}\"] = data\n",
    "\n",
    "    # Optional: Print the total sum for each day to verify\n",
    "    print(f\"Day {i+1} Total Sum: {np.sum(data):.2f}\")\n",
    "\n",
    "# Optional: Display the first few rows of the DataFrame\n",
    "print(filtered.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered.drop(columns=[\"Day 366\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "supermarkets = pd.read_csv('generated_timeseries.csv', index_col=0)\n",
    "supermarkets[\"waste\"] = supermarkets[\"excess_kg\"] * 1.7798\n",
    "supermarkets.drop(columns=[\"excess_kg\"], inplace=True)\n",
    "\n",
    "supermarkets[\"waste\"] = supermarkets[\"waste\"] / 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('final_data.csv', index_col=0)\n",
    "filtered_up = data[data[\"type\"] == \"Supermarket\"].reset_index()\n",
    "filtered_up[\"waste\"] = filtered_up[\"waste\"] / 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have a DataFrame 'filtered_up' with 'name' and 'waste' columns\n",
    "# For illustration, here's how you might define 'filtered_up':\n",
    "# filtered_up = pd.DataFrame({\n",
    "#     'name': ['Store A', 'Store B', 'Store C', 'Store D'],\n",
    "#     'waste': [100, 200, 0, 150]  # Notice that 'Store C' has a mean waste of 0\n",
    "# })\n",
    "\n",
    "# Extract names and waste values\n",
    "names = filtered_up['name'].tolist()\n",
    "waste_means = filtered_up['waste'].values  # Mean for each name\n",
    "\n",
    "# Number of days\n",
    "N_days = 365\n",
    "\n",
    "# Initialize the DataFrame with the 'name' column\n",
    "data = pd.DataFrame({'name': names})\n",
    "\n",
    "# Calculate variances:\n",
    "# - For entries where waste_mean is 0, variance is set to 5\n",
    "# - For other entries, variance is 0.1 * waste_mean\n",
    "waste_variances = np.where(waste_means == 0, 5, 0.1 * waste_means)\n",
    "\n",
    "# Standard deviations are the square root of variances\n",
    "waste_stddevs = np.sqrt(waste_variances)\n",
    "\n",
    "# Generate samples for each day\n",
    "for day in range(1, N_days + 1):\n",
    "    day_name = f'Day {day}'\n",
    "    # Sample from normal distribution for each name\n",
    "    samples = np.random.normal(loc=waste_means, scale=waste_stddevs)\n",
    "    # Ensure no negative values (since waste can't be negative)\n",
    "    samples = np.clip(samples, a_min=0, a_max=None)\n",
    "    # Add the samples to the DataFrame\n",
    "    data[day_name] = samples\n",
    "\n",
    "# Display the first few rows of the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pulp import LpProblem, LpMaximize, LpVariable, lpSum, LpInteger\n",
    "\n",
    "\n",
    "lambda_penalty = 0.4\n",
    "distance_penalty = 0.2\n",
    "\n",
    "\n",
    "def milp_optimization(supply, demand, distance):\n",
    "    model = LpProblem(\"MIP_Optimization\", LpMaximize)\n",
    "    x = {(i, j): LpVariable(f\"x_{i}_{j}\", lowBound=0, cat=LpInteger) for i in supply for j in demand}\n",
    "\n",
    "    model += lpSum(x[i, j] for i in supply for j in demand) \\\n",
    "             - lambda_penalty * lpSum((supply[i] - lpSum(x[i, j] for j in demand)) for i in supply) \\\n",
    "             - distance_penalty * lpSum(distance[i, j] * x[i, j] for i in supply for j in demand)\n",
    "\n",
    "    for i in supply:\n",
    "        model += lpSum(x[i, j] for j in demand) <= supply[i]\n",
    "    for j in demand:\n",
    "        model += lpSum(x[i, j] for i in supply) <= demand[j]\n",
    "\n",
    "    model.solve()\n",
    "    output = {}\n",
    "    for key in x:\n",
    "        val = x[key].varValue\n",
    "        #if val != 0.0:\n",
    "        output[key] = val\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "geospatial_data = pd.read_csv('final_data.csv', index_col=0)\n",
    "geospatial_data = geospatial_data.drop(columns=[\"demand\", \"supply\", \"waste\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geospatial_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pulp import LpProblem, LpMaximize, LpVariable, lpSum, LpInteger\n",
    "\n",
    "# Set penalty parameters\n",
    "lambda_penalty = 0.4\n",
    "distance_penalty = 2.0\n",
    "\n",
    "# Define the optimization function\n",
    "def milp_optimization(supply, demand, distance_dict):\n",
    "    # Create the model\n",
    "    model = LpProblem(\"MIP_Optimization\", LpMaximize)\n",
    "    \n",
    "    # Decision variables: Amount allocated from supermarket i to food bank j\n",
    "    x = {\n",
    "        (i, j): LpVariable(f\"x_{i}_{j}\", lowBound=0)\n",
    "        for i in supply for j in demand\n",
    "    }\n",
    "    \n",
    "    # Objective function\n",
    "    model += (\n",
    "        lpSum(x[i, j] for i in supply for j in demand)\n",
    "        - lambda_penalty * lpSum(\n",
    "            (supply[i] - lpSum(x[i, j] for j in demand)) for i in supply\n",
    "        )\n",
    "        - distance_penalty * lpSum(\n",
    "            distance_dict.get((i, j), 0) * x[i, j] for i in supply for j in demand\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Supply constraints: Total allocations from a supermarket cannot exceed its supply\n",
    "    for i in supply:\n",
    "        model += lpSum(x[i, j] for j in demand) <= supply[i]\n",
    "    \n",
    "    # Demand constraints: Total allocations to a food bank cannot exceed its demand\n",
    "    for j in demand:\n",
    "        model += lpSum(x[i, j] for i in supply) <= demand[j]\n",
    "    \n",
    "    # Solve the model\n",
    "    model.solve()\n",
    "    \n",
    "    # Extract the results\n",
    "    output = {}\n",
    "    for (i, j) in x:\n",
    "        val = x[(i, j)].varValue\n",
    "        if val > 0:\n",
    "            output[(i, j)] = val\n",
    "    return output\n",
    "\n",
    "# Haversine distance function\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calculate the Haversine distance between two points.\n",
    "    Input coordinates are in decimal degrees.\n",
    "    Output distance is in kilometers.\n",
    "    \"\"\"\n",
    "    # Earth's radius in kilometers\n",
    "    R = 6371.0\n",
    "    \n",
    "    # Convert decimal degrees to radians\n",
    "    lat1_rad, lon1_rad = np.radians(lat1), np.radians(lon1)\n",
    "    lat2_rad, lon2_rad = np.radians(lat2), np.radians(lon2)\n",
    "    \n",
    "    # Differences in coordinates\n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "    \n",
    "    # Haversine formula\n",
    "    a = np.sin(dlat / 2.0)**2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(dlon / 2.0)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    \n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "# Assuming 'geospatial_data' DataFrame is already loaded\n",
    "# Ensure 'name' is a column; reset index if necessary\n",
    "geospatial_data = geospatial_data.reset_index(drop=False)\n",
    "\n",
    "# Clean names to remove leading/trailing whitespace\n",
    "geospatial_data['name'] = geospatial_data['name'].str.strip()\n",
    "\n",
    "# Separate supermarkets and food banks\n",
    "supermarkets = geospatial_data[geospatial_data['type'] == 'Supermarket'].copy()\n",
    "foodbanks = geospatial_data[geospatial_data['type'] == 'Foodbank'].copy()\n",
    "\n",
    "# Compute distances between every supermarket and every food bank\n",
    "# Prepare arrays for vectorized computation\n",
    "supermarkets_coords = supermarkets[['name', 'lat', 'lng']].reset_index(drop=True)\n",
    "foodbanks_coords = foodbanks[['name', 'lat', 'lng']].reset_index(drop=True)\n",
    "\n",
    "# Create a list to store distances\n",
    "distance_records = []\n",
    "\n",
    "# Compute distances\n",
    "for idx_sup, sup_row in supermarkets_coords.iterrows():\n",
    "    sup_name = sup_row['name']\n",
    "    sup_lat = sup_row['lat']\n",
    "    sup_lng = sup_row['lng']\n",
    "    \n",
    "    # Compute distances to all food banks\n",
    "    distances = haversine_distance(\n",
    "        sup_lat,\n",
    "        sup_lng,\n",
    "        foodbanks_coords['lat'].values,\n",
    "        foodbanks_coords['lng'].values\n",
    "    )\n",
    "    \n",
    "    # Store distances\n",
    "    for idx_fb, fb_row in foodbanks_coords.iterrows():\n",
    "        fb_name = fb_row['name']\n",
    "        distance = distances[idx_fb]\n",
    "        distance_records.append({\n",
    "            'supermarket': sup_name,\n",
    "            'foodbank': fb_name,\n",
    "            'distance_km': distance\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "distance_df = pd.DataFrame(distance_records)\n",
    "\n",
    "# Create a distance dictionary for quick lookup\n",
    "distance_dict = distance_df.set_index(['supermarket', 'foodbank'])['distance_km'].to_dict()\n",
    "\n",
    "\n",
    "\n",
    "N_days = 30\n",
    "\n",
    "# Run the optimization for each day\n",
    "results = {}  # To store results for each day\n",
    "\n",
    "for day in range(1, N_days + 1):\n",
    "    day_name = f'Day {day}'\n",
    "    print(f\"Processing {day_name}...\")\n",
    "    \n",
    "    # Prepare supply for the day\n",
    "    supply_series = data.set_index('name')[day_name]\n",
    "    supply_series = supply_series[supply_series > 0]  # Filter out zero or negative supplies\n",
    "    supply = supply_series.to_dict()\n",
    "    \n",
    "    # Prepare demand for the day\n",
    "    demand_series = filtered.set_index('name')[day_name]\n",
    "    demand_series = demand_series[demand_series > 0]  # Filter out zero or negative demands\n",
    "    demand = demand_series.to_dict()\n",
    "    \n",
    "    # Check if there's supply and demand\n",
    "    if not supply or not demand:\n",
    "        print(f\"No supply or demand on {day_name}, skipping optimization.\")\n",
    "        continue\n",
    "    \n",
    "    # Run the optimization\n",
    "    result = milp_optimization(supply, demand, distance_dict)\n",
    "    results[day_name] = result\n",
    "    \n",
    "    \n",
    "    # Optional: Display the allocations\n",
    "    # print(f\"Allocations for {day_name}:\")\n",
    "    # for (i, j), qty in result.items():\n",
    "    #     print(f\" - Supply from {i} to {j}: {qty} units\")\n",
    "\n",
    "# Compile all allocations into a single DataFrame\n",
    "allocation_records = []\n",
    "for day_name, allocations in results.items():\n",
    "    for (i, j), qty in allocations.items():\n",
    "        allocation_records.append({\n",
    "            'day': day_name,\n",
    "            'supermarket': i,\n",
    "            'foodbank': j,\n",
    "            'quantity': qty\n",
    "        })\n",
    "\n",
    "allocations_df = pd.DataFrame(allocation_records)\n",
    "\n",
    "# Optionally, save the results to a CSV file\n",
    "# allocations_df.to_csv('allocations_all_days.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the allocations\n",
    "print(allocations_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allocations_df[allocations_df[\"foodbank\"] == \"Bounds Green\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allocations_df[allocations_df[\"day\"] == \"Day 1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'pos', 'supermarket_names', and 'foodbank_names' are already defined\n",
    "\n",
    "# For each day:\n",
    "unique_days = allocations_df['day'].unique()\n",
    "for day in unique_days:\n",
    "    print(f\"Processing {day}...\")\n",
    "    daily_allocations = allocations_df[allocations_df['day'] == day].copy()\n",
    "    \n",
    "    # Group allocations to avoid duplicates\n",
    "    edge_data = daily_allocations.groupby(['supermarket', 'foodbank'])['quantity'].sum().reset_index()\n",
    "    \n",
    "    # Build edge list and weights\n",
    "    edges = []\n",
    "    edge_weights = {}\n",
    "    for _, row in edge_data.iterrows():\n",
    "        s = row['supermarket']\n",
    "        f = row['foodbank']\n",
    "        quantity = row['quantity']\n",
    "        edges.append((s, f))\n",
    "        edge_weights[(s, f)] = quantity\n",
    "    \n",
    "    # Verify number of edges\n",
    "    print(f\"Number of transactions on {day}: {len(edges)}\")\n",
    "    \n",
    "    # Create a new graph for the day's allocations\n",
    "    G_day = nx.Graph()\n",
    "    G_day.add_nodes_from(supermarket_names, node_type='supermarket')\n",
    "    G_day.add_nodes_from(foodbank_names, node_type='foodbank')\n",
    "    G_day.add_edges_from(edges)\n",
    "    \n",
    "    # Calculate foodbank satisfaction levels (if applicable)\n",
    "    # ... (same as before)\n",
    "    \n",
    "    # Create edge traces\n",
    "    edge_traces = []\n",
    "    for (s, f), quantity in edge_weights.items():\n",
    "        x0, y0 = pos[s]\n",
    "        x1, y1 = pos[f]\n",
    "        width = quantity / 20  # Adjust scaling_factor as needed\n",
    "        edge_trace = go.Scatter(\n",
    "            x=[x0, x1], y=[y0, y1],\n",
    "            line=dict(width=width, color='#888'),\n",
    "            hoverinfo='text',\n",
    "            text=f\"{s} to {f}: {quantity:.2f}\",\n",
    "            mode='lines')\n",
    "        edge_traces.append(edge_trace)\n",
    "    \n",
    "    # Prepare node traces\n",
    "    # Nodes involved in transactions\n",
    "    supermarkets_involved = set(edge_data['supermarket'])\n",
    "    foodbanks_involved = set(edge_data['foodbank'])\n",
    "    \n",
    "    # Node sizes\n",
    "    supermarket_sizes = [15 if node in supermarkets_involved else 10 for node in supermarket_names]\n",
    "    foodbank_sizes = [15 if node in foodbanks_involved else 10 for node in foodbank_names]\n",
    "    \n",
    "    # Supermarket trace\n",
    "    supermarket_trace = go.Scatter(\n",
    "        x=[pos[node][0] for node in supermarket_names],\n",
    "        y=[pos[node][1] for node in supermarket_names],\n",
    "        mode='markers',\n",
    "        hoverinfo='text',\n",
    "        text=supermarket_names,\n",
    "        marker=dict(\n",
    "            color='blue',\n",
    "            size=supermarket_sizes,\n",
    "            line_width=1),\n",
    "        name='Supermarkets')\n",
    "    \n",
    "    # Foodbank trace\n",
    "    foodbank_trace = go.Scatter(\n",
    "        x=[pos[node][0] for node in foodbank_names],\n",
    "        y=[pos[node][1] for node in foodbank_names],\n",
    "        mode='markers',\n",
    "        hoverinfo='text',\n",
    "        text=foodbank_names,\n",
    "        marker=dict(\n",
    "            color='green',\n",
    "            size=foodbank_sizes,\n",
    "            line_width=1),\n",
    "        name='Foodbanks')\n",
    "    \n",
    "    # Create figure\n",
    "    fig = go.Figure(data=edge_traces + [supermarket_trace, foodbank_trace])\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=f'Food Distribution Network - {day}',\n",
    "        showlegend=False,\n",
    "        hovermode='closest',\n",
    "        margin=dict(b=20, l=5, r=5, t=40),\n",
    "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))\n",
    "    \n",
    "    # Show the figure\n",
    "    fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
